{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaAIDev/Hugging_Face_LLM_models/blob/main/smart_contract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__rpXv076ldi",
        "outputId": "4a41d2e6-eb2f-485b-f4a7-23c346eed1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-stack\n",
            "  Downloading llama_stack-0.0.63-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting blobfile (from llama-stack)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting fire (from llama-stack)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.27.0)\n",
            "Collecting llama-models>=0.0.63 (from llama-stack)\n",
            "  Downloading llama_models-0.0.63-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting llama-stack-client>=0.0.63 (from llama-stack)\n",
            "  Downloading llama_stack_client-0.0.63-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from llama-stack) (3.0.48)\n",
            "Collecting python-dotenv (from llama-stack)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from llama-stack) (13.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from llama-stack) (75.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (3.1.4)\n",
            "Collecting tiktoken (from llama-models>=0.0.63->llama-stack)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (11.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (3.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (8.1.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (1.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (2.2.2)\n",
            "Collecting pyaml (from llama-stack-client>=0.0.63->llama-stack)\n",
            "  Downloading pyaml-24.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-stack) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama-stack) (2.27.1)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->llama-stack)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (2.2.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (5.3.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llama-stack) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (2.18.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->llama-stack-client>=0.0.63->llama-stack) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->llama-models>=0.0.63->llama-stack) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2024.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-models>=0.0.63->llama-stack) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.0.63->llama-stack) (1.17.0)\n",
            "Downloading llama_stack-0.0.63-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.7/463.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_models-0.0.63-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_stack_client-0.0.63-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.12.1-py3-none-any.whl (25 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=c6d162a69036dc99df3137872a2aeabe1e29ca4a0031e22fb6c1e3fa6199186d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: python-dotenv, pycryptodomex, pyaml, fire, tiktoken, blobfile, llama-stack-client, llama-models, llama-stack\n",
            "Successfully installed blobfile-3.0.0 fire-0.7.0 llama-models-0.0.63 llama-stack-0.0.63 llama-stack-client-0.0.63 pyaml-24.12.1 pycryptodomex-3.21.0 python-dotenv-1.0.1 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMW0BwszA884"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeeBfln_A-f5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20EtRzfF7Bgo",
        "outputId": "f764481b-e888-4901-d672-0007f4c765a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-stack in /usr/local/lib/python3.10/dist-packages (0.0.63)\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (from llama-stack) (3.0.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.7.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.27.0)\n",
            "Requirement already satisfied: llama-models>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.0.63)\n",
            "Requirement already satisfied: llama-stack-client>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.0.63)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from llama-stack) (3.0.48)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from llama-stack) (1.0.1)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from llama-stack) (13.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from llama-stack) (75.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (3.1.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (0.8.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.63->llama-stack) (11.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (3.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (8.1.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (1.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (2.2.2)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (24.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from llama-stack-client>=0.0.63->llama-stack) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-stack) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama-stack) (2.27.1)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (3.21.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (2.2.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (5.3.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llama-stack) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (2.18.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->llama-stack-client>=0.0.63->llama-stack) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->llama-models>=0.0.63->llama-stack) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-stack-client>=0.0.63->llama-stack) (2024.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-models>=0.0.63->llama-stack) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.0.63->llama-stack) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-stack -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtFd6MEh7G0h",
        "outputId": "5ca20074-098f-4fff-cc5a-b217bf69563d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "\u001b[1m\u001b[97m| Model Descriptor                        | Hugging Face Repo                                   | Context Length |\u001b[0m\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-8B                             | meta-llama/Llama-3.1-8B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-70B                            | meta-llama/Llama-3.1-70B                            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp8                  | meta-llama/Llama-3.1-405B                           | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B                           | meta-llama/Llama-3.1-405B-FP8                       | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp16                 | meta-llama/Llama-3.1-405B                           | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-8B-Instruct                    | meta-llama/Llama-3.1-8B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-70B-Instruct                   | meta-llama/Llama-3.1-70B-Instruct                   | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp8         | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct                  | meta-llama/Llama-3.1-405B-Instruct-FP8              | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp16        | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B                             | meta-llama/Llama-3.2-1B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B                             | meta-llama/Llama-3.2-3B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision                     | meta-llama/Llama-3.2-11B-Vision                     | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision                     | meta-llama/Llama-3.2-90B-Vision                     | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct                    | meta-llama/Llama-3.2-1B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct                    | meta-llama/Llama-3.2-3B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8     | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8 | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8     | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8 | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision-Instruct            | meta-llama/Llama-3.2-11B-Vision-Instruct            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision-Instruct            | meta-llama/Llama-3.2-90B-Vision-Instruct            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.3-70B-Instruct                   | meta-llama/Llama-3.3-70B-Instruct                   | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-11B-Vision                | meta-llama/Llama-Guard-3-11B-Vision                 | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B:int4                   | meta-llama/Llama-Guard-3-1B-INT4                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B                        | meta-llama/Llama-Guard-3-1B                         | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B                        | meta-llama/Llama-Guard-3-8B                         | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B:int8                   | meta-llama/Llama-Guard-3-8B-INT8                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-2-8B                        | meta-llama/Llama-Guard-2-8B                         | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "!llama model list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MRp4q5l7Wc0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH4X4SiJ7QEM",
        "outputId": "22d94ce6-ba7f-42c4-e518-1ac44186030f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "\u001b[1m\u001b[97m| Model Descriptor                        | Hugging Face Repo                                   | Context Length |\u001b[0m\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-7b                              | meta-llama/Llama-2-7b                               | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-13b                             | meta-llama/Llama-2-13b                              | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-70b                             | meta-llama/Llama-2-70b                              | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-7b-chat                         | meta-llama/Llama-2-7b-chat                          | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-13b-chat                        | meta-llama/Llama-2-13b-chat                         | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-2-70b-chat                        | meta-llama/Llama-2-70b-chat                         | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-3-8B                              | meta-llama/Llama-3-8B                               | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-3-70B                             | meta-llama/Llama-3-70B                              | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-3-8B-Instruct                     | meta-llama/Llama-3-8B-Instruct                      | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-3-70B-Instruct                    | meta-llama/Llama-3-70B-Instruct                     | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-8B                             | meta-llama/Llama-3.1-8B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-70B                            | meta-llama/Llama-3.1-70B                            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp8                  | meta-llama/Llama-3.1-405B                           | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B                           | meta-llama/Llama-3.1-405B-FP8                       | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp16                 | meta-llama/Llama-3.1-405B                           | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-8B-Instruct                    | meta-llama/Llama-3.1-8B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-70B-Instruct                   | meta-llama/Llama-3.1-70B-Instruct                   | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp8         | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct                  | meta-llama/Llama-3.1-405B-Instruct-FP8              | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp16        | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B                             | meta-llama/Llama-3.2-1B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B                             | meta-llama/Llama-3.2-3B                             | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision                     | meta-llama/Llama-3.2-11B-Vision                     | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision                     | meta-llama/Llama-3.2-90B-Vision                     | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct                    | meta-llama/Llama-3.2-1B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct                    | meta-llama/Llama-3.2-3B-Instruct                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8     | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8 | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8     | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8 | 8K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision-Instruct            | meta-llama/Llama-3.2-11B-Vision-Instruct            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision-Instruct            | meta-llama/Llama-3.2-90B-Vision-Instruct            | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama3.3-70B-Instruct                   | meta-llama/Llama-3.3-70B-Instruct                   | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-11B-Vision                | meta-llama/Llama-Guard-3-11B-Vision                 | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B:int4                   | meta-llama/Llama-Guard-3-1B-INT4                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B                        | meta-llama/Llama-Guard-3-1B                         | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B                        | meta-llama/Llama-Guard-3-8B                         | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B:int8                   | meta-llama/Llama-Guard-3-8B-INT8                    | 128K           |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Llama-Guard-2-8B                        | meta-llama/Llama-Guard-2-8B                         | 4K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n",
            "| Prompt-Guard-86M                        | meta-llama/Prompt-Guard-86M                         | 2K             |\n",
            "+-----------------------------------------+-----------------------------------------------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "!llama model list --show-all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cshfY8Uj7Xwp",
        "outputId": "c46b5834-e826-4c9e-cac2-b6cedc38c4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide the signed URL for model Llama3.2-1B you received via email after visiting https://www.llama.com/llama-downloads/ (e.g., https://llama3-1.llamameta.net/*?Policy...): https://llama3-2-lightweight.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicGJzNGJyZTdubncxb3hibHBydWs0ZWdxIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvbGxhbWEzLTItbGlnaHR3ZWlnaHQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTgwMzM0N319fV19&Signature=TcoNPyJ5v56Qcj2BNzoLIgKbMytL2pDpo0f8tmzutdRnBnJFyl0qr-v9cHzPCvOJfx3WHBN7UHtjOJl2wIygQ6n0FMswC%7Em9NXvNb6PT6juysBsqthDePGzgY5nOYuJW-0H08wgQF7zDfJiETopg3R59A%7EGx-OEYqSW46K4DZbjmA%7E8dNwypGKoYpuLwmdr9MY4ALONefHy7LRFHtmlevFenx5JI6WnsMIqp%7ERMUv53b9GllwQkxusqyvy8FMGYBIFEeuXjMx-zRBofYJI1Iw65LCqb2gZqg8ZAvTgOwJIJBDAlWHoztdx4ZtEUpmlOUwkmhb2IzI%7Ee052%7ELDX1KSg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1291721111952285\n",
            "\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m    \u001b[35m0.0%\u001b[0m  \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m    \u001b[35m0.0%\u001b[0m  \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m    \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m    \u001b[35m0.0%\u001b[0m  \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m        \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m          \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m        \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m          \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m        \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m          \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m        \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m          \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32mAlready downloaded \u001b[0m\u001b[32m/root/.llama/checkpoints/Llama3.2-1B/\u001b[0m\u001b[32mtokenizer.model\u001b[0m\n",
            "\u001b[1;34mDownloading checklist.chk\u001b[0m        \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m          \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   \u001b[35m0.0%\u001b[0m \u001b[32m0/0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32mAlready downloaded \u001b[0m\u001b[32m/root/.llama/checkpoints/Llama3.2-1B/\u001b[0m\u001b[32mparams.json\u001b[0m\n",
            "\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32mAlready downloaded \u001b[0m\u001b[32m/root/.llama/checkpoints/Llama3.2-1B/\u001b[0m\u001b[32mchecklist.chk\u001b[0m\n",
            "\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m0.0%\u001b[0m   \u001b[32m0/0 bytes \u001b[0m \u001b[31m?\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m156/156 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB   \u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m220/220 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m156/156 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB   \u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m220/220 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32mAlready downloaded \u001b[0m\u001b[32m/root/.llama/checkpoints/Llama3.2-1B/\u001b[0m\u001b[32mconsolidated.00.pth\u001b[0m\n",
            "\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m156/156 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB   \u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m220/220 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mDownloading checklist.chk\u001b[0m       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m156/156 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading tokenizer.model\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.2/2.2 MB   \u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading params.json\u001b[0m         \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m220/220 bytes\u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[1;34mDownloading consolidated.00.pth\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m \u001b[32m2.5/2.5 GB   \u001b[0m - \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32m\n",
            "Successfully downloaded model to /root/.llama/checkpoints/Llama3.2-1B\u001b[0m\n",
            "\u001b[97m\n",
            "View MD5 checksum files at: /root/.llama/checkpoints/Llama3.2-1B/checklist.chk\u001b[0m\n",
            "\u001b[33m\n",
            "[Optionally] To run MD5 checksums, use the following command: llama model verify-download --model-id Llama3.2-1B\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!llama model download --source meta --model-id Llama3.2-1B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaX2523FBAps",
        "outputId": "bbab859a-7823-47e2-9925-be943f9b844e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuU6rj-WX8lb",
        "outputId": "f34c5ca7-6ec1-4045-ca15-615f4c079d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate peft datasets torch sentencepiece\n",
        "!pip install transformers\n",
        "!pip install --upgrade transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFIJmqCIpRz8",
        "outputId": "1f993716-2112-4e9c-bdf1-a04c21af6454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   255    0   255    0     0    183      0 --:--:--  0:00:01 --:--:--   183\n"
          ]
        }
      ],
      "source": [
        "!curl -o Llama-3.2-1B.zip \"https://llama3-2-lightweight.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiMmk4NnNkazdyYXlnbTFhcDI2dHY3cGxwIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvbGxhbWEzLTItbGlnaHR3ZWlnaHQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTgwNDQ2Nn19fV19&Signature=DqKEJkket6L-2V0j8CR1sZI9kMDr%7EpQUMs-o1VGWivZXRjvMnQSKZGl3tJUwhzLpyAicX9KPauYLuSojLdKDYOsY5o57N0CkdPm10w0g8Rbdm%7E4s%7Ea5h7iB00MeuaphzSLaqfyVYQdTuMggsE4kIX99GuyI3fp7JlymBnnW7A05c9VYqu-n79NuwhodaVsrjpmToHKArWeiNLzHmy7Yh7IPRM6Q%7ECUDijavpjxojPpeYGYfr-YuuJxpBS11MrM3A9%7EePNmYLZrV2krUyPn5lRsa%7EzkIW922V9Ezcfj0MQiKR%7E27o5%7EkfvnYDit7a3WFgmrENWx%7ENSj9Xu7097fuwIA__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=603367765887268\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkozY3i3vahq",
        "outputId": "a17c87c7-8efe-4620-8041-0598f4fc0730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 243 Dec 31 07:59 Llama-3.2-1B.zip\n",
            "Llama-3.2-1B.zip: XML 1.0 document, ASCII text\n"
          ]
        }
      ],
      "source": [
        "# Check the file size\n",
        "!ls -lh Llama-3.2-1B.zip\n",
        "\n",
        "# Inspect the file type\n",
        "!file Llama-3.2-1B.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbDRs7MhrPKN",
        "outputId": "8e2e95c5-2cd1-41ae-c4c2-515dcc679761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Llama-3.2-1B.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of Llama-3.2-1B.zip or\n",
            "        Llama-3.2-1B.zip.zip, and cannot find Llama-3.2-1B.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!unzip Llama-3.2-1B.zip -d /content/Llama-3.2-1B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IevKnafngAMA",
        "outputId": "02af4d62-01ff-4349-ccae-7b943a0d8c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: bitsandbytes 0.45.0\n",
            "Uninstalling bitsandbytes-0.45.0:\n",
            "  Successfully uninstalled bitsandbytes-0.45.0\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y bitsandbytes\n",
        "!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtOwBEL1Yb6",
        "outputId": "694e8467-9300-4568-f04b-273a816fbd16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "token = \"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\"  # Replace with your token\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "41c10267754f4105a34ef2a1ee779c12",
            "fed735a579094c2c8a9f0680a4b64656",
            "5339da30f1674f8e8c13810af973201e",
            "212c0a3abcff472f9e2dfe558b3dc8bb",
            "25bb8516e332459f8874aef5bf38055c",
            "e093011e9b4f4ae0a62df8e8040f903c",
            "c49b3454af5446aea188f384558b2ed4",
            "b8e739a357ba4a4ea5195b755d909066",
            "8f86a2b13c964b98b6c955a0f773f6c9",
            "0f77f083141d4f3e9930e25962088621",
            "16beea2680034a4dae676ef2ad09b3cc",
            "48ef1994755f49f091a7735afdb9d07a",
            "07f968ddb6514c079d67877ab7dfc480",
            "f29137e996ff459e9e11b5d5fedbe8df",
            "bc535aa1dee143d6bc3c32d2cbc382d6",
            "fbfcf400f4cf45e98c56fc230b577780",
            "be4c8a137dd841d0aa42bf51ff03f009",
            "8c676db2c3e447138ea09e2c60ee6ee2",
            "66a40990654c467d8ea035d89623b611",
            "3fdea9c208a34d399fb26fd9d9696630",
            "2840760100594d6584d1bbeaad023f3b",
            "91c4b063067040d0851686d0c14023c9"
          ]
        },
        "id": "BcpsWFm45Epi",
        "outputId": "27d7989e-68a9-4fa0-91b7-c0c59210428b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41c10267754f4105a34ef2a1ee779c12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48ef1994755f49f091a7735afdb9d07a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'contract_name': 'UserWallet', 'file_path': 'UserWallet.sol', 'contract_address': '0x84dabbb8999f508ce1cbb7057d260c74c6c9815c', 'language': 'Solidity', 'source_code': 'pragma solidity ^0.4.10;\\r\\n\\r\\n// Copyright 2017 Bittrex\\r\\n\\r\\ncontract AbstractSweeper {\\r\\n    function sweep(address token, uint amount) returns (bool);\\r\\n\\r\\n    function () { throw; }\\r\\n\\r\\n    Controller controller;\\r\\n\\r\\n    function AbstractSweeper(address _controller) {\\r\\n        controller = Controller(_controller);\\r\\n    }\\r\\n\\r\\n    modifier canSweep() {\\r\\n        if (msg.sender != controller.authorizedCaller() && msg.sender != controller.owner()) throw;\\r\\n        if (controller.halted()) throw;\\r\\n        _;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract Token {\\r\\n    function balanceOf(address a) returns (uint) {\\r\\n        (a);\\r\\n        return 0;\\r\\n    }\\r\\n\\r\\n    function transfer(address a, uint val) returns (bool) {\\r\\n        (a);\\r\\n        (val);\\r\\n        return false;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract DefaultSweeper is AbstractSweeper {\\r\\n    function DefaultSweeper(address controller)\\r\\n             AbstractSweeper(controller) {}\\r\\n\\r\\n    function sweep(address _token, uint _amount)\\r\\n    canSweep\\r\\n    returns (bool) {\\r\\n        bool success = false;\\r\\n        address destination = controller.destination();\\r\\n\\r\\n        if (_token != address(0)) {\\r\\n            Token token = Token(_token);\\r\\n            uint amount = _amount;\\r\\n            if (amount > token.balanceOf(this)) {\\r\\n                return false;\\r\\n            }\\r\\n\\r\\n            success = token.transfer(destination, amount);\\r\\n        }\\r\\n        else {\\r\\n            uint amountInWei = _amount;\\r\\n            if (amountInWei > this.balance) {\\r\\n                return false;\\r\\n            }\\r\\n\\r\\n            success = destination.send(amountInWei);\\r\\n        }\\r\\n\\r\\n        if (success) {\\r\\n            controller.logSweep(this, destination, _token, _amount);\\r\\n        }\\r\\n        return success;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract UserWallet {\\r\\n    AbstractSweeperList sweeperList;\\r\\n    function UserWallet(address _sweeperlist) {\\r\\n        sweeperList = AbstractSweeperList(_sweeperlist);\\r\\n    }\\r\\n\\r\\n    function () public payable { }\\r\\n\\r\\n    function tokenFallback(address _from, uint _value, bytes _data) {\\r\\n        (_from);\\r\\n        (_value);\\r\\n        (_data);\\r\\n     }\\r\\n\\r\\n    function sweep(address _token, uint _amount)\\r\\n    returns (bool) {\\r\\n        (_amount);\\r\\n        return sweeperList.sweeperOf(_token).delegatecall(msg.data);\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract AbstractSweeperList {\\r\\n    function sweeperOf(address _token) returns (address);\\r\\n}\\r\\n\\r\\ncontract Controller is AbstractSweeperList {\\r\\n    address public owner;\\r\\n    address public authorizedCaller;\\r\\n\\r\\n    address public destination;\\r\\n\\r\\n    bool public halted;\\r\\n\\r\\n    event LogNewWallet(address receiver);\\r\\n    event LogSweep(address indexed from, address indexed to, address indexed token, uint amount);\\r\\n    \\r\\n    modifier onlyOwner() {\\r\\n        if (msg.sender != owner) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    modifier onlyAuthorizedCaller() {\\r\\n        if (msg.sender != authorizedCaller) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    modifier onlyAdmins() {\\r\\n        if (msg.sender != authorizedCaller && msg.sender != owner) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    function Controller() \\r\\n    {\\r\\n        owner = msg.sender;\\r\\n        destination = msg.sender;\\r\\n        authorizedCaller = msg.sender;\\r\\n    }\\r\\n\\r\\n    function changeAuthorizedCaller(address _newCaller) onlyOwner {\\r\\n        authorizedCaller = _newCaller;\\r\\n    }\\r\\n\\r\\n    function changeDestination(address _dest) onlyOwner {\\r\\n        destination = _dest;\\r\\n    }\\r\\n\\r\\n    function changeOwner(address _owner) onlyOwner {\\r\\n        owner = _owner;\\r\\n    }\\r\\n\\r\\n    function makeWallet() onlyAdmins returns (address wallet)  {\\r\\n        wallet = address(new UserWallet(this));\\r\\n        LogNewWallet(wallet);\\r\\n    }\\r\\n\\r\\n    function halt() onlyAdmins {\\r\\n        halted = true;\\r\\n    }\\r\\n\\r\\n    function start() onlyOwner {\\r\\n        halted = false;\\r\\n    }\\r\\n\\r\\n    address public defaultSweeper = address(new DefaultSweeper(this));\\r\\n    mapping (address => address) sweepers;\\r\\n\\r\\n    function addSweeper(address _token, address _sweeper) onlyOwner {\\r\\n        sweepers[_token] = _sweeper;\\r\\n    }\\r\\n\\r\\n    function sweeperOf(address _token) returns (address) {\\r\\n        address sweeper = sweepers[_token];\\r\\n        if (sweeper == 0) sweeper = defaultSweeper;\\r\\n        return sweeper;\\r\\n    }\\r\\n\\r\\n    function logSweep(address from, address to, address token, uint amount) {\\r\\n        LogSweep(from, to, token, amount);\\r\\n    }\\r\\n}', 'abi': '[{\"constant\":false,\"inputs\":[{\"name\":\"_token\",\"type\":\"address\"},{\"name\":\"_amount\",\"type\":\"uint256\"}],\"name\":\"sweep\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_from\",\"type\":\"address\"},{\"name\":\"_value\",\"type\":\"uint256\"},{\"name\":\"_data\",\"type\":\"bytes\"}],\"name\":\"tokenFallback\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"inputs\":[{\"name\":\"_sweeperlist\",\"type\":\"address\"}],\"payable\":false,\"type\":\"constructor\"},{\"payable\":true,\"type\":\"fallback\"}]', 'compiler_version': 'v0.4.11+commit.68ef5810', 'optimization_used': True, 'runs': 200.0, 'constructor_arguments': '000000000000000000000000a3C1E324CA1ce40db73eD6026c4A177F099B5770', 'evm_version': 'Default', 'library': '', 'license_type': '', 'proxy': False, 'implementation': '', 'swarm_source': 'bzzr://4cdd69fdcf3cf6cbee9677fe380fa5f044048aa9e060ec5619a21ca5a5bd4cd1'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"ASSERT-KTH/DISL\", 'decomposed',split=\"train\")\n",
        "\n",
        "# Check a sample\n",
        "print(dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68k6pLiF6SZl",
        "outputId": "5b1f99e3-2522-4e32-c3f0-69dfb696464c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'contract_name': 'UserWallet', 'file_path': 'UserWallet.sol', 'contract_address': '0x84dabbb8999f508ce1cbb7057d260c74c6c9815c', 'language': 'Solidity', 'source_code': 'pragma solidity ^0.4.10;\\r\\n\\r\\n// Copyright 2017 Bittrex\\r\\n\\r\\ncontract AbstractSweeper {\\r\\n    function sweep(address token, uint amount) returns (bool);\\r\\n\\r\\n    function () { throw; }\\r\\n\\r\\n    Controller controller;\\r\\n\\r\\n    function AbstractSweeper(address _controller) {\\r\\n        controller = Controller(_controller);\\r\\n    }\\r\\n\\r\\n    modifier canSweep() {\\r\\n        if (msg.sender != controller.authorizedCaller() && msg.sender != controller.owner()) throw;\\r\\n        if (controller.halted()) throw;\\r\\n        _;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract Token {\\r\\n    function balanceOf(address a) returns (uint) {\\r\\n        (a);\\r\\n        return 0;\\r\\n    }\\r\\n\\r\\n    function transfer(address a, uint val) returns (bool) {\\r\\n        (a);\\r\\n        (val);\\r\\n        return false;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract DefaultSweeper is AbstractSweeper {\\r\\n    function DefaultSweeper(address controller)\\r\\n             AbstractSweeper(controller) {}\\r\\n\\r\\n    function sweep(address _token, uint _amount)\\r\\n    canSweep\\r\\n    returns (bool) {\\r\\n        bool success = false;\\r\\n        address destination = controller.destination();\\r\\n\\r\\n        if (_token != address(0)) {\\r\\n            Token token = Token(_token);\\r\\n            uint amount = _amount;\\r\\n            if (amount > token.balanceOf(this)) {\\r\\n                return false;\\r\\n            }\\r\\n\\r\\n            success = token.transfer(destination, amount);\\r\\n        }\\r\\n        else {\\r\\n            uint amountInWei = _amount;\\r\\n            if (amountInWei > this.balance) {\\r\\n                return false;\\r\\n            }\\r\\n\\r\\n            success = destination.send(amountInWei);\\r\\n        }\\r\\n\\r\\n        if (success) {\\r\\n            controller.logSweep(this, destination, _token, _amount);\\r\\n        }\\r\\n        return success;\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract UserWallet {\\r\\n    AbstractSweeperList sweeperList;\\r\\n    function UserWallet(address _sweeperlist) {\\r\\n        sweeperList = AbstractSweeperList(_sweeperlist);\\r\\n    }\\r\\n\\r\\n    function () public payable { }\\r\\n\\r\\n    function tokenFallback(address _from, uint _value, bytes _data) {\\r\\n        (_from);\\r\\n        (_value);\\r\\n        (_data);\\r\\n     }\\r\\n\\r\\n    function sweep(address _token, uint _amount)\\r\\n    returns (bool) {\\r\\n        (_amount);\\r\\n        return sweeperList.sweeperOf(_token).delegatecall(msg.data);\\r\\n    }\\r\\n}\\r\\n\\r\\ncontract AbstractSweeperList {\\r\\n    function sweeperOf(address _token) returns (address);\\r\\n}\\r\\n\\r\\ncontract Controller is AbstractSweeperList {\\r\\n    address public owner;\\r\\n    address public authorizedCaller;\\r\\n\\r\\n    address public destination;\\r\\n\\r\\n    bool public halted;\\r\\n\\r\\n    event LogNewWallet(address receiver);\\r\\n    event LogSweep(address indexed from, address indexed to, address indexed token, uint amount);\\r\\n    \\r\\n    modifier onlyOwner() {\\r\\n        if (msg.sender != owner) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    modifier onlyAuthorizedCaller() {\\r\\n        if (msg.sender != authorizedCaller) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    modifier onlyAdmins() {\\r\\n        if (msg.sender != authorizedCaller && msg.sender != owner) throw; \\r\\n        _;\\r\\n    }\\r\\n\\r\\n    function Controller() \\r\\n    {\\r\\n        owner = msg.sender;\\r\\n        destination = msg.sender;\\r\\n        authorizedCaller = msg.sender;\\r\\n    }\\r\\n\\r\\n    function changeAuthorizedCaller(address _newCaller) onlyOwner {\\r\\n        authorizedCaller = _newCaller;\\r\\n    }\\r\\n\\r\\n    function changeDestination(address _dest) onlyOwner {\\r\\n        destination = _dest;\\r\\n    }\\r\\n\\r\\n    function changeOwner(address _owner) onlyOwner {\\r\\n        owner = _owner;\\r\\n    }\\r\\n\\r\\n    function makeWallet() onlyAdmins returns (address wallet)  {\\r\\n        wallet = address(new UserWallet(this));\\r\\n        LogNewWallet(wallet);\\r\\n    }\\r\\n\\r\\n    function halt() onlyAdmins {\\r\\n        halted = true;\\r\\n    }\\r\\n\\r\\n    function start() onlyOwner {\\r\\n        halted = false;\\r\\n    }\\r\\n\\r\\n    address public defaultSweeper = address(new DefaultSweeper(this));\\r\\n    mapping (address => address) sweepers;\\r\\n\\r\\n    function addSweeper(address _token, address _sweeper) onlyOwner {\\r\\n        sweepers[_token] = _sweeper;\\r\\n    }\\r\\n\\r\\n    function sweeperOf(address _token) returns (address) {\\r\\n        address sweeper = sweepers[_token];\\r\\n        if (sweeper == 0) sweeper = defaultSweeper;\\r\\n        return sweeper;\\r\\n    }\\r\\n\\r\\n    function logSweep(address from, address to, address token, uint amount) {\\r\\n        LogSweep(from, to, token, amount);\\r\\n    }\\r\\n}', 'abi': '[{\"constant\":false,\"inputs\":[{\"name\":\"_token\",\"type\":\"address\"},{\"name\":\"_amount\",\"type\":\"uint256\"}],\"name\":\"sweep\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_from\",\"type\":\"address\"},{\"name\":\"_value\",\"type\":\"uint256\"},{\"name\":\"_data\",\"type\":\"bytes\"}],\"name\":\"tokenFallback\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"inputs\":[{\"name\":\"_sweeperlist\",\"type\":\"address\"}],\"payable\":false,\"type\":\"constructor\"},{\"payable\":true,\"type\":\"fallback\"}]', 'compiler_version': 'v0.4.11+commit.68ef5810', 'optimization_used': True, 'runs': 200.0, 'constructor_arguments': '000000000000000000000000a3C1E324CA1ce40db73eD6026c4A177F099B5770', 'evm_version': 'Default', 'library': '', 'license_type': '', 'proxy': False, 'implementation': '', 'swarm_source': 'bzzr://4cdd69fdcf3cf6cbee9677fe380fa5f044048aa9e060ec5619a21ca5a5bd4cd1', 'input_ids': [128000, 14396, 9356, 25, 220, 15, 87, 5833, 67, 370, 6194, 22889, 24, 69, 19869, 346, 16, 66, 6194, 21469, 22, 67, 11387, 66, 5728, 66, 21, 66, 25643, 20, 66, 198, 32215, 279, 2592, 2082, 25, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [128000, 6143, 73263, 6440, 15, 13, 19, 13, 605, 1967, 322, 3028, 220, 679, 22, 426, 1468, 38639, 881, 20871, 13822, 50, 906, 10653, 987, 262, 734, 24021, 15797, 4037, 11, 2687, 3392, 8, 4780, 320, 2707, 3155, 262, 734, 1754, 314, 2571, 26, 2616, 262, 9970, 6597, 1967, 262, 734, 13822, 50, 906, 10653, 15797, 721, 7299, 8, 987, 286, 6597, 284, 9970, 2551, 7299, 741, 262, 2616, 262, 23575, 649, 50, 49642, 368, 987, 286, 422, 320, 3316, 27828, 976, 6597, 16714, 1534, 59835, 368, 1024, 3835, 27828, 976, 6597, 26772, 2189, 2571, 464, 286, 422, 320, 7299, 870, 62334, 2189, 2571, 464, 286, 721, 464, 262, 1720, 2634, 20871, 9857, 987, 262, 734, 8335, 2173, 15797, 264, 8, 4780, 320, 2557, 8, 987, 286, 320, 64, 741, 286, 471, 220, 15, 464, 262, 2616, 262, 734, 8481, 15797, 264, 11, 2687, 1062, 8, 4780, 320, 2707, 8, 987, 286, 320, 64, 741, 286, 320, 838, 741, 286, 471, 905, 464, 262, 1720, 2634, 20871, 8058, 50, 906, 10653, 374, 13822, 50, 906, 10653, 987, 262, 734, 8058, 50, 906, 10653, 15797, 6597, 1240, 1835, 13822, 50, 906, 10653, 41945, 8, 71946, 262, 734, 24021, 15797, 721, 5963, 11, 2687, 721, 6173, 1240, 262, 649, 50, 49642, 319, 262, 4780, 320, 2707, 8, 987, 286, 1845, 2450, 284, 905, 464, 286, 2686, 9284, 284, 6597, 36118, 7466, 286, 422, 5570, 5963, 976, 2686, 7, 15, 595, 987, 310, 9857, 4037, 284, 9857, 2551, 5963, 741, 310, 2687, 3392, 284, 721, 6173, 464, 310, 422, 320, 6173, 871, 4037, 40178, 2173, 1420, 595, 987, 394, 471, 905, 464, 310, 2616, 310, 2450, 284, 4037, 50528, 49176, 11, 3392, 741, 286, 1720, 286, 775, 987, 310, 2687, 3392, 644, 87293, 284, 721, 6173, 464, 310, 422, 320, 6173, 644, 87293, 871, 420, 40178, 8, 987, 394, 471, 905, 464, 310, 2616, 310, 2450, 284, 9284, 5331, 35089, 644, 87293, 741, 286, 2616, 286, 422, 320, 5748, 8, 987, 310, 6597, 1699, 50, 49642, 1420, 11, 9284, 11, 721, 5963, 11, 721, 6173, 741, 286, 1720, 286, 471, 2450, 464, 262, 1720, 2634, 20871, 2724, 39359, 987, 262, 13822, 50, 906, 10653, 861, 10769, 10653, 861, 464, 262, 734, 2724, 39359, 15797, 721, 82, 906, 10653, 1638, 8, 987, 286, 10769, 10653, 861, 284, 13822, 50, 906, 10653, 861, 2551, 82, 906, 10653, 1638, 741, 262, 2616, 262, 734, 1754, 586, 45691, 314, 2616, 262, 734, 4037, 88306, 15797, 721, 1527, 11, 2687, 721, 970, 11, 5943, 721, 695, 8, 987, 286, 5570, 1527, 741, 286, 5570, 970, 741, 286, 5570, 695, 741, 257, 2616, 262, 734, 24021, 15797, 721, 5963, 11, 2687, 721, 6173, 1240, 262, 4780, 320, 2707, 8, 987, 286, 5570, 6173, 741, 286, 471, 10769, 10653, 861, 516, 906, 10653, 2173, 2551, 5963, 570, 29327, 6797, 8282, 2245, 741, 262, 1720, 2634, 20871, 13822, 50, 906, 10653, 861, 987, 262, 734, 10769, 10653, 2173, 15797, 721, 5963, 8, 4780, 320, 5102, 741, 2634, 20871, 9970, 374, 13822, 50, 906, 10653, 861, 987, 262, 2686, 586, 6506, 464, 262, 2686]}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the model name and token\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "token = \"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\"  # Replace with your Hugging Face token\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\n",
        "\n",
        "# Add a padding token if not already defined\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Preprocesses the dataset by tokenizing inputs and labels.\n",
        "\n",
        "    Args:\n",
        "    - examples: A dictionary with \"contract_address\" and \"source_code\".\n",
        "\n",
        "    Returns:\n",
        "    - model_inputs: Tokenized inputs and labels.\n",
        "    \"\"\"\n",
        "    inputs = [f\"Contract Address: {addr}\\nGenerate the source code:\" for addr in examples[\"contract_address\"]]\n",
        "    targets = examples[\"source_code\"]\n",
        "\n",
        "    # Tokenize inputs and labels\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Align input and labels\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Reduce dataset size to the first 10,000 examples\n",
        "small_dataset = dataset.select(range(min(10000, len(dataset))))\n",
        "\n",
        "# Apply preprocessing to the smaller dataset\n",
        "processed_dataset = small_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Check a few examples after processing\n",
        "print(processed_dataset[0])  # Print the first example for verification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zspS34an87Bb",
        "outputId": "6c8d8c52-5db9-46a1-bb7d-af022258a5b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA model loaded and configured on CPU.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import bitsandbytes as bnb  # Verify bitsandbytes installation\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    use_auth_token=token,\n",
        "    device_map=None,  # Disable auto GPU mapping\n",
        "    load_in_8bit=False  # Do not load in 8-bit since it's designed for CUDA\n",
        ")\n",
        "\n",
        "# Apply LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Rank of LoRA layers\n",
        "    lora_alpha=32,  # Scaling factor\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
        "    lora_dropout=0.1,  # Dropout rate\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Apply LoRA to the model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Move model to CPU explicitly\n",
        "model.to(\"cpu\")\n",
        "\n",
        "# Test the configuration\n",
        "print(\"LoRA model loaded and configured on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "61214c3032d64e7db76d6a11d71418f7",
            "c32b3212d20b40cc8879f148b7c2b2f9",
            "71990cf67784467e9c91efc34c60d3d1",
            "2ebf3611fe6947ee90f8b9a5caa4aca7",
            "caaed7796d3a4e76b1c545c54793985f",
            "3d2eb0d64d2d4058ae5411179ad18222",
            "92f8d4320d4e4a229d33e893066bb203",
            "c820503f99204f8388a65fe3fa2e9fa3",
            "0a8565c9db074957942c0445f1b4cfda",
            "a255391bca704182bceda09e3364141b",
            "696fa79c06b045c492b975d6be1e7bfe"
          ]
        },
        "id": "7s2qIc4E9BCr",
        "outputId": "445a2981-5cec-4808-dfd1-102caca66b33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61214c3032d64e7db76d6a11d71418f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-ab10927e0f5b>:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",  # Save directory\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=False,  # Disable mixed precision for CPU or if not using a GPU\n",
        ")\n",
        "\n",
        "# Assuming 'dataset' is your loaded dataset\n",
        "# Reduce the dataset size to the first 10,000 examples\n",
        "small_dataset = dataset.select(range(min(10000, len(dataset))))  # Ensure 'dataset' is defined\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_dataset = small_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Split the dataset into train and evaluation sets\n",
        "small_dataset_split = processed_dataset.train_test_split(test_size=0.2)  # Split the dataset\n",
        "\n",
        "# Define the Trainer, providing both train and eval datasets\n",
        "trainer = Trainer(\n",
        "    model=model,  # Your preloaded model\n",
        "    args=training_args,\n",
        "    train_dataset=small_dataset_split[\"train\"],  # Use the training split\n",
        "    eval_dataset=small_dataset_split[\"test\"],  # Use the evaluation split\n",
        "    tokenizer=tokenizer,  # Use the tokenizer\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcOv1EkwjbYF",
        "outputId": "94752028-c3b4-4381-d19c-431f7918aeaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-Tuned LLaMA Contract Address to Source Code Generator\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Generated Source Code:\n",
            "Error generating source code: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Define your Hugging Face token\n",
        "huggingface_token = \"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\"  # Replace with your token\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-3.2-1B\",\n",
        "    use_auth_token=huggingface_token\n",
        ")\n",
        "\n",
        "# Load the model with authentication\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3.2-1B\",\n",
        "    use_auth_token=huggingface_token,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# Ensure the model is running on CPU\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "# Function to generate source code based on contract address\n",
        "def generate_source_code(contract_address):\n",
        "    input_text = f\"Contract Address: {contract_address}\\nGenerate the source code:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Generate output with controlled decoding parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=512,\n",
        "        temperature=0.7,  # Control randomness\n",
        "        top_p=0.9,       # Use nucleus sampling for diversity\n",
        "        repetition_penalty=1.2,  # Penalize repetitive phrases\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result\n",
        "\n",
        "# Main loop for user input\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Fine-Tuned LLaMA Contract Address to Source Code Generator\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    while True:\n",
        "        contract_address = input(\"Enter the contract address (or type 'exit' to quit): \").strip()\n",
        "        if contract_address.lower() == \"exit\":\n",
        "            print(\"Exiting program.\")\n",
        "            break\n",
        "\n",
        "        # Generate and display the source code\n",
        "        print(\"\\nGenerated Source Code:\")\n",
        "        try:\n",
        "            source_code = generate_source_code(contract_address)\n",
        "            print(source_code)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating source code: {e}\")\n",
        "        print(\"-\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOsZtQPlgYSlQR8nvyZS8H0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07f968ddb6514c079d67877ab7dfc480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4c8a137dd841d0aa42bf51ff03f009",
            "placeholder": "​",
            "style": "IPY_MODEL_8c676db2c3e447138ea09e2c60ee6ee2",
            "value": "Resolving data files: 100%"
          }
        },
        "0a8565c9db074957942c0445f1b4cfda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f77f083141d4f3e9930e25962088621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16beea2680034a4dae676ef2ad09b3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "212c0a3abcff472f9e2dfe558b3dc8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f77f083141d4f3e9930e25962088621",
            "placeholder": "​",
            "style": "IPY_MODEL_16beea2680034a4dae676ef2ad09b3cc",
            "value": " 18/18 [00:00&lt;00:00, 25.39it/s]"
          }
        },
        "25bb8516e332459f8874aef5bf38055c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2840760100594d6584d1bbeaad023f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebf3611fe6947ee90f8b9a5caa4aca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a255391bca704182bceda09e3364141b",
            "placeholder": "​",
            "style": "IPY_MODEL_696fa79c06b045c492b975d6be1e7bfe",
            "value": " 10000/10000 [01:21&lt;00:00, 126.91 examples/s]"
          }
        },
        "3d2eb0d64d2d4058ae5411179ad18222": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fdea9c208a34d399fb26fd9d9696630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41c10267754f4105a34ef2a1ee779c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed735a579094c2c8a9f0680a4b64656",
              "IPY_MODEL_5339da30f1674f8e8c13810af973201e",
              "IPY_MODEL_212c0a3abcff472f9e2dfe558b3dc8bb"
            ],
            "layout": "IPY_MODEL_25bb8516e332459f8874aef5bf38055c"
          }
        },
        "48ef1994755f49f091a7735afdb9d07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07f968ddb6514c079d67877ab7dfc480",
              "IPY_MODEL_f29137e996ff459e9e11b5d5fedbe8df",
              "IPY_MODEL_bc535aa1dee143d6bc3c32d2cbc382d6"
            ],
            "layout": "IPY_MODEL_fbfcf400f4cf45e98c56fc230b577780"
          }
        },
        "5339da30f1674f8e8c13810af973201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e739a357ba4a4ea5195b755d909066",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f86a2b13c964b98b6c955a0f773f6c9",
            "value": 18
          }
        },
        "61214c3032d64e7db76d6a11d71418f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c32b3212d20b40cc8879f148b7c2b2f9",
              "IPY_MODEL_71990cf67784467e9c91efc34c60d3d1",
              "IPY_MODEL_2ebf3611fe6947ee90f8b9a5caa4aca7"
            ],
            "layout": "IPY_MODEL_caaed7796d3a4e76b1c545c54793985f"
          }
        },
        "66a40990654c467d8ea035d89623b611": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696fa79c06b045c492b975d6be1e7bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71990cf67784467e9c91efc34c60d3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c820503f99204f8388a65fe3fa2e9fa3",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a8565c9db074957942c0445f1b4cfda",
            "value": 10000
          }
        },
        "8c676db2c3e447138ea09e2c60ee6ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f86a2b13c964b98b6c955a0f773f6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91c4b063067040d0851686d0c14023c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92f8d4320d4e4a229d33e893066bb203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a255391bca704182bceda09e3364141b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e739a357ba4a4ea5195b755d909066": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc535aa1dee143d6bc3c32d2cbc382d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2840760100594d6584d1bbeaad023f3b",
            "placeholder": "​",
            "style": "IPY_MODEL_91c4b063067040d0851686d0c14023c9",
            "value": " 18/18 [00:00&lt;00:00, 383.46it/s]"
          }
        },
        "be4c8a137dd841d0aa42bf51ff03f009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32b3212d20b40cc8879f148b7c2b2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2eb0d64d2d4058ae5411179ad18222",
            "placeholder": "​",
            "style": "IPY_MODEL_92f8d4320d4e4a229d33e893066bb203",
            "value": "Map: 100%"
          }
        },
        "c49b3454af5446aea188f384558b2ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c820503f99204f8388a65fe3fa2e9fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caaed7796d3a4e76b1c545c54793985f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e093011e9b4f4ae0a62df8e8040f903c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29137e996ff459e9e11b5d5fedbe8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a40990654c467d8ea035d89623b611",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fdea9c208a34d399fb26fd9d9696630",
            "value": 18
          }
        },
        "fbfcf400f4cf45e98c56fc230b577780": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed735a579094c2c8a9f0680a4b64656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e093011e9b4f4ae0a62df8e8040f903c",
            "placeholder": "​",
            "style": "IPY_MODEL_c49b3454af5446aea188f384558b2ed4",
            "value": "Resolving data files: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}